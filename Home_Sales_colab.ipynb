{"cells":[{"cell_type":"code","source":["import os\n","\n","# Specify the Spark version\n","spark_version = 'spark-3.4.0'\n","os.environ['SPARK_VERSION'] = spark_version\n","\n","# Install Java and other required packages\n","!apt-get update\n","!apt-get install -y openjdk-11-jdk-headless wget > /dev/null\n","\n","# Download and install Spark (use a different mirror)\n","!wget -q \"https://archive.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\"\n","!tar xf \"$SPARK_VERSION-bin-hadoop3.tgz\"\n","\n","# Install findspark package\n","!pip install -q findspark\n","\n","# Set environment variables for Java and Spark\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n","\n","# Initialize Spark\n","import findspark\n","findspark.init()\n","\n","# Confirm Spark is working\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n","spark\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":636},"id":"eq_cRtcAo9td","outputId":"58f36e3f-87d5-4139-bf84-ee6d18936f88","executionInfo":{"status":"ok","timestamp":1726365199240,"user_tz":240,"elapsed":40081,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.org (18.239.18.39)] [Co\r                                                                                                    \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","\r                                                                                                    \rGet:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","\r                                                                                                    \rGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Ign:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Get:11 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n","Get:12 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,108 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,541 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,439 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.7 kB]\n","Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,150 kB]\n","Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,267 kB]\n","Get:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,030 kB]\n","Get:20 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,313 kB]\n","Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,575 kB]\n","Fetched 24.9 MB in 8s (3,257 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"]},{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x780c49a0bb50>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://b7c707f66cc3:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.4.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>pyspark-shell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":1}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"2XbWNf1Te5fM","executionInfo":{"status":"ok","timestamp":1726365211912,"user_tz":240,"elapsed":316,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}}},"outputs":[],"source":["# Import packages\n","from pyspark.sql import SparkSession\n","import time\n","\n","# Create a SparkSession\n","spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"wOJqxG_RPSwp","executionInfo":{"status":"ok","timestamp":1726365260465,"user_tz":240,"elapsed":561,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}}},"outputs":[],"source":["# 1. Read in the AWS S3 bucket into a DataFrame.\n","from pyspark import SparkFiles\n","url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\"\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"RoljcJ7WPpnm","executionInfo":{"status":"ok","timestamp":1726365442613,"user_tz":240,"elapsed":12306,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}}},"outputs":[],"source":["# 2. Create a temporary view of the DataFrame.\n","spark.sparkContext.addFile(url)\n","df = spark.read.csv(SparkFiles.get(\"home_sales_revised.csv\"), header=True, inferSchema=True)\n","df.createOrReplaceTempView(\"home_sales\")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"L6fkwOeOmqvq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726365909936,"user_tz":240,"elapsed":4628,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}},"outputId":"9a8ddcd4-c9c1-4459-b75d-75c2466d1159"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------------+\n","|year|average_price|\n","+----+-------------+\n","|2019|     300263.7|\n","|2020|    298353.78|\n","|2021|    301819.44|\n","|2022|    296363.88|\n","+----+-------------+\n","\n"]}],"source":["# 3. What is the average price for a four bedroom house sold per year, rounded to two decimal places?\n","query = \"\"\"\n","    SELECT\n","        YEAR(date) AS year,\n","        ROUND(AVG(price), 2) AS average_price\n","    FROM home_sales\n","    WHERE bedrooms = 4\n","    GROUP BY YEAR(date)\n","    ORDER BY year\n","\"\"\"\n","\n","average_price_per_year = spark.sql(query)\n","average_price_per_year.show()\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"l8p_tUS8h8it","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726366035382,"user_tz":240,"elapsed":1384,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}},"outputId":"785c3ad8-0765-4830-99b7-428040a578e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+-------------+\n","|year_built|average_price|\n","+----------+-------------+\n","|      2010|    292859.62|\n","|      2011|    291117.47|\n","|      2012|    293683.19|\n","|      2013|    295962.27|\n","|      2014|    290852.27|\n","|      2015|     288770.3|\n","|      2016|    290555.07|\n","|      2017|    292676.79|\n","+----------+-------------+\n","\n"]}],"source":["# 4. What is the average price of a home for each year the home was built,\n","# that have 3 bedrooms and 3 bathrooms, rounded to two decimal places?\n","query = \"\"\"\n","    SELECT\n","        date_built AS year_built,\n","        ROUND(AVG(price), 2) AS average_price\n","    FROM home_sales\n","    WHERE bedrooms = 3 AND bathrooms = 3\n","    GROUP BY date_built\n","    ORDER BY year_built\n","\"\"\"\n","\n","average_price_per_year_built = spark.sql(query)\n","average_price_per_year_built.show()\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Y-Eytz64liDU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726366086613,"user_tz":240,"elapsed":1662,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}},"outputId":"e0adfd4b-b412-41be-a471-f3e9469086e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+-------------+\n","|year_built|average_price|\n","+----------+-------------+\n","|      2010|    285010.22|\n","|      2011|    276553.81|\n","|      2012|    307539.97|\n","|      2013|    303676.79|\n","|      2014|    298264.72|\n","|      2015|    297609.97|\n","|      2016|     293965.1|\n","|      2017|    280317.58|\n","+----------+-------------+\n","\n"]}],"source":["# 5. What is the average price of a home for each year the home was built,\n","# that have 3 bedrooms, 3 bathrooms, with two floors,\n","# and are greater than or equal to 2,000 square feet, rounded to two decimal places?\n","query = \"\"\"\n","    SELECT\n","        date_built AS year_built,\n","        ROUND(AVG(price), 2) AS average_price\n","    FROM home_sales\n","    WHERE bedrooms = 3\n","      AND bathrooms = 3\n","      AND floors = 2\n","      AND sqft_living >= 2000\n","    GROUP BY date_built\n","    ORDER BY year_built\n","\"\"\"\n","\n","average_price_filtered = spark.sql(query)\n","average_price_filtered.show()\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GUrfgOX1pCRd","outputId":"1e01333a-9540-4a1a-b779-4d3b7ebd7209","executionInfo":{"status":"ok","timestamp":1726366233661,"user_tz":240,"elapsed":904,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------------+\n","|view|average_price|\n","+----+-------------+\n","| 100|    1026669.5|\n","|  99|   1061201.42|\n","|  98|   1053739.33|\n","|  97|   1129040.15|\n","|  96|   1017815.92|\n","|  95|    1054325.6|\n","|  94|    1033536.2|\n","|  93|   1026006.06|\n","|  92|    970402.55|\n","|  91|   1137372.73|\n","|  90|   1062654.16|\n","|  89|   1107839.15|\n","|  88|   1031719.35|\n","|  87|    1072285.2|\n","|  86|   1070444.25|\n","|  85|   1056336.74|\n","|  84|   1117233.13|\n","|  83|   1033965.93|\n","|  82|    1063498.0|\n","|  81|   1053472.79|\n","+----+-------------+\n","only showing top 20 rows\n","\n","--- 0.6364293098449707 seconds ---\n"]}],"source":["# 6. What is the average price of a home per \"view\" rating, rounded to two decimal places,\n","# having an average home price greater than or equal to $350,000? Order by descending view rating.\n","# Although this is a small dataset, determine the run time for this query.\n","query = \"\"\"\n","    SELECT\n","        view,\n","        ROUND(AVG(price), 2) AS average_price\n","    FROM home_sales\n","    GROUP BY view\n","    HAVING AVG(price) >= 350000\n","    ORDER BY view DESC\n","\"\"\"\n","\n","start_time = time.time()\n","\n","average_price_per_view = spark.sql(query)\n","average_price_per_view.show()\n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"KAhk3ZD2tFy8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726366286152,"user_tz":240,"elapsed":296,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}},"outputId":"f309e73a-a860-4a45-c6ae-909a3630c787"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[id: string, date: date, date_built: int, price: int, bedrooms: int, bathrooms: int, sqft_living: int, sqft_lot: int, floors: int, waterfront: int, view: int]"]},"metadata":{},"execution_count":13}],"source":["# 7. Cache the the temporary table home_sales.\n","df.cache()"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"4opVhbvxtL-i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726366289029,"user_tz":240,"elapsed":325,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}},"outputId":"86415454-259f-498b-f9eb-52ea28165a02"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":14}],"source":["# 8. Check if the table is cached.\n","spark.catalog.isCached('home_sales')"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5GnL46lwTSEk","outputId":"22412ccb-9e57-4aeb-fc16-d21ce086a81e","executionInfo":{"status":"ok","timestamp":1726366357915,"user_tz":240,"elapsed":667,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------------+\n","|view|average_price|\n","+----+-------------+\n","| 100|    1026669.5|\n","|  99|   1061201.42|\n","|  98|   1053739.33|\n","|  97|   1129040.15|\n","|  96|   1017815.92|\n","|  95|    1054325.6|\n","|  94|    1033536.2|\n","|  93|   1026006.06|\n","|  92|    970402.55|\n","|  91|   1137372.73|\n","|  90|   1062654.16|\n","|  89|   1107839.15|\n","|  88|   1031719.35|\n","|  87|    1072285.2|\n","|  86|   1070444.25|\n","|  85|   1056336.74|\n","|  84|   1117233.13|\n","|  83|   1033965.93|\n","|  82|    1063498.0|\n","|  81|   1053472.79|\n","+----+-------------+\n","only showing top 20 rows\n","\n","--- 0.5569663047790527 seconds ---\n"]}],"source":["# 9. Using the cached data, run the last query above, that calculates\n","# the average price of a home per \"view\" rating, rounded to two decimal places,\n","# having an average home price greater than or equal to $350,000.\n","# Determine the runtime and compare it to the uncached runtime.\n","\n","start_time = time.time()\n","\n","query_cached = \"\"\"\n","    SELECT\n","        view,\n","        ROUND(AVG(price), 2) AS average_price\n","    FROM home_sales\n","    GROUP BY view\n","    HAVING AVG(price) >= 350000\n","    ORDER BY view DESC\n","\"\"\"\n","\n","average_price_per_view_cached = spark.sql(query_cached)\n","average_price_per_view_cached.show()\n","\n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Qm12WN9isHBR","executionInfo":{"status":"ok","timestamp":1726366476062,"user_tz":240,"elapsed":4475,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}}},"outputs":[],"source":["# 10. Partition by the \"date_built\" field on the formatted parquet home sales data\n","parquet_output_path = \"/content/home_sales_partitioned_by_date_built\"\n","df.write.partitionBy(\"date_built\").parquet(parquet_output_path)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"AZ7BgY61sRqY","executionInfo":{"status":"ok","timestamp":1726366493378,"user_tz":240,"elapsed":634,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}}},"outputs":[],"source":["# 11. Read the parquet formatted data.\n","df_parquet = spark.read.parquet(parquet_output_path)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"J6MJkHfvVcvh","executionInfo":{"status":"ok","timestamp":1726366504516,"user_tz":240,"elapsed":270,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}}},"outputs":[],"source":["# 12. Create a temporary table for the parquet data.\n","df_parquet.createOrReplaceTempView(\"home_sales_parquet\")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_Vhb52rU1Sn","outputId":"d5718196-2055-4a57-da04-ece0229774db","executionInfo":{"status":"ok","timestamp":1726366552643,"user_tz":240,"elapsed":1079,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------------+\n","|view|average_price|\n","+----+-------------+\n","| 100|    1026669.5|\n","|  99|   1061201.42|\n","|  98|   1053739.33|\n","|  97|   1129040.15|\n","|  96|   1017815.92|\n","|  95|    1054325.6|\n","|  94|    1033536.2|\n","|  93|   1026006.06|\n","|  92|    970402.55|\n","|  91|   1137372.73|\n","|  90|   1062654.16|\n","|  89|   1107839.15|\n","|  88|   1031719.35|\n","|  87|    1072285.2|\n","|  86|   1070444.25|\n","|  85|   1056336.74|\n","|  84|   1117233.13|\n","|  83|   1033965.93|\n","|  82|    1063498.0|\n","|  81|   1053472.79|\n","+----+-------------+\n","only showing top 20 rows\n","\n","--- 0.7699339389801025 seconds ---\n"]}],"source":["# 13. Using the parquet DataFrame, run the last query above, that calculates\n","# the average price of a home per \"view\" rating, rounded to two decimal places,\n","# having an average home price greater than or equal to $350,000.\n","# Determine the runtime and compare it to the cached runtime.\n","\n","start_time = time.time()\n","\n","query_parquet = \"\"\"\n","    SELECT\n","        view,\n","        ROUND(AVG(price), 2) AS average_price\n","    FROM home_sales_parquet\n","    GROUP BY view\n","    HAVING AVG(price) >= 350000\n","    ORDER BY view DESC\n","\"\"\"\n","\n","average_price_per_view_parquet = spark.sql(query_parquet)\n","average_price_per_view_parquet.show()\n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"hjjYzQGjtbq8","executionInfo":{"status":"ok","timestamp":1726366579640,"user_tz":240,"elapsed":313,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}}},"outputs":[],"source":["# 14. Uncache the home_sales temporary table.\n","spark.catalog.uncacheTable(\"home_sales\")"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"Sy9NBvO7tlmm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726366640562,"user_tz":240,"elapsed":290,"user":{"displayName":"Kayla Blais","userId":"14095571201205541746"}},"outputId":"acca2e66-434e-4634-c7a6-567f1b9f4854"},"outputs":[{"output_type":"stream","name":"stdout","text":["The home_sales table still cached: True/False: False\n"]}],"source":["# 15. Check if the home_sales is no longer cached\n","is_cached = spark.catalog.isCached(\"home_sales\")\n","print(f\"The home_sales table still cached: True/False: {is_cached}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Si-BNruRUGK3"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"nteract":{"version":"0.28.0"}},"nbformat":4,"nbformat_minor":0}